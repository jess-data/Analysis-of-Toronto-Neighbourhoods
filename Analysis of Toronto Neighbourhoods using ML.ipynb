{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Toronto Neighbourhoods using Machine Learning\n",
    "_This is a notebook by Jessica Uwoghiren._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Introduction\n",
    "In 2019, 35% of new Canadian immigrants chose to settle in the City of Toronto. The City has 140 neighbourhoods, so, as a new immigrant, a vital question to answer is “What neighbourhood do I settle in?”. The aim of this project is to group Toronto neighborhoods in order of desirability using Machine Learning and Data Visualization techniques. I performed my analysis using on the following criteria:\n",
    "\n",
    "•\tTotal number of **Essential Venues** in each neighbourhood\n",
    "\n",
    "•\t**Primary and Secondary Benchmarks**: Primary benchmarks considered were Unemployment rate, Crime rate and COVID-19 rates while the Secondary benchmark was housing price for a one-bedroom apartment in each neighbourhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Contents\n",
    "\n",
    "[1. Import Libraries](#1.-Import-Libraries)\n",
    "\n",
    "[2. Import Neighbourhoods Datasets](#2.-Import-Neighbourhoods-Datasets)\n",
    "\n",
    "[3. Data Cleaning](#3.-Data-Cleaning)   \n",
    "\n",
    "[4. Data Exploration](#4.-Data-Exploration)\n",
    "\n",
    "[5. Toronto Neighbourhoods Venues Data Mining](#5.-Toronto-Neighbourhoods-Venues-Data-Mining)\n",
    "\n",
    "[6. Analyzing Toronto Neighbourhoods & Venues](#6.-Analyzing-Toronto-Neighbourhoods-&-Venues)\n",
    "\n",
    "[7. Machine Learning Algorithm (k-Means)](#7.-Machine-Learning-Algorithm-(k-Means))\n",
    "\n",
    "[8. Clustering Neighbourhoods by Total number of Essential Venues](#8.-Clustering-Neighbourhoods-by-Total-number-of-Essential-Venues)\n",
    "\n",
    "[9. Visualizing Toronto Neighbourhoods Clusters](#9.-Visualizing-Toronto-Neighbourhoods-Clusters)\n",
    "\n",
    "[10. Import and Clean Primary Benchmarks Datasets](#10.-Import-and-Clean-Primary-Benchmarks-Datasets)\n",
    "\n",
    "[11. Clustering Neighbourhoods by Primary Benchmarks](#11.-Clustering-Neighbourhoods-by-Primary-Benchmarks)\n",
    "\n",
    "[12. Clustering using Secondary Benchmark (Housing Prices)](#12.-Clustering-using-Secondary-Benchmark-(Housing-Prices))\n",
    "\n",
    "[13. Final Results and Visualizations](#13.-Final-Results-and-Visualizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the libraries to be used in this notebook. I prefer to do this at the initial stage and added more libraries as I went along on the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # library to handle data in a vectorized manner\n",
    "\n",
    "import pandas as pd  # library for data analsysis\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "import requests  # library to handle requests\n",
    "from pandas.io.json import json_normalize  # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import geocoder  # import geocoder\n",
    "import plotly.express as px\n",
    "import geopandas as gpd # to strore geospatial data\n",
    "import chart_studio\n",
    "import chart_studio.plotly as py # for exporting Plotly visualizations to Chart Studio\n",
    "import plotly.graph_objects as go # to ploty Plotly graph objects\n",
    "import plotly.io as pio # Plotly renderer\n",
    "import matplotlib.pyplot as plt # Import Matplotlib for visualizations\n",
    "import datapane as dp # for exporting map visualizations to Datapane\n",
    "from plotly.subplots import make_subplots # to make multiple Plotly plots in one instance\n",
    "\n",
    "import plotly.offline as pyo # Set notebook mode to work in offline\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 2. Import Neighbourhoods Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the dataset contianing the 140 Toronto neighbourhoods and their Neighbourhoods IDs were imported to the notebook. The GeoJSON file was also imported and converted to a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_df = pd.read_excel(\n",
    "    r'C:\\Users\\Osas\\Downloads\\Data analysis\\Capstone\\CityofToronto_COVID-19_NeighbourhoodData.xlsx',\n",
    "    sheet_name='All Cases and Rates by Neighbou') # Dataset with Neighbourhood names and ID\n",
    "toronto_geo = r'C:\\Users\\Osas\\Downloads\\Data analysis\\Capstone\\Neighbourhoods.geojson'  # geojson file\n",
    "\n",
    "print('Datasets downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets imported in Section 2 were processed for further analysis. Missing values were removed as some cells were empty. This did not impact all the 140 neighbourhoods. I also sliced only the relevant columns required for the analysis as I only required the Neighbourhood ID and Name columns. It is also important to mention that the Neighbourhood ID was considered as the Primary key for all the dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Neighbourhoods dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_df.dropna(axis=0, inplace=True) # Drop empty rows\n",
    "toronto_df = toronto_df.astype({\"Neighbourhood ID\": int}) # Convert Neighbourhood ID to Int type\n",
    "toronto_df = toronto_df.iloc[:, 0:2] # Slice only relevant columns\n",
    "toronto_df.head() # Display top 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Geopandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_gdf = gpd.read_file(toronto_geo) # Read GEOJSON file to a Geopandas dataframe\n",
    "toronto_gdf.head() # Display initial dataframe to see what outcome is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_gdf = toronto_gdf.iloc[:, 5:]  # Slice dataframe for only relevant attributes\n",
    "toronto_gdf.rename(columns={'AREA_LONG_CODE': 'Neighbourhood ID'},\n",
    "                   inplace=True)  # Rename Area_Long_Code as it is same as Neighbourhood ID\n",
    "toronto_gdf.drop(labels=['AREA_DESC', 'OBJECTID', 'X', 'Y', 'AREA_NAME'],\n",
    "                 axis=1, inplace=True) # Drop irrelevant columns\n",
    "toronto_gdf.head() # Display top 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Merge Geopandas and Neighbourhoods Dataset\n",
    "The Geopandas dataframe and the Neighbourhoods dataset were merged into one Geopandas dataframe. This dataframe was very important for map visualizations on Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_gdf=toronto_gdf.merge(toronto_df,\n",
    "                              on='Neighbourhood ID') # Use Merge function for both dataset\n",
    "cols = toronto_gdf.columns.tolist() # Convert column names to a List\n",
    "cols = cols[-1:] + cols[:-1] # Move last column to first column\n",
    "toronto_gdf=toronto_gdf[cols] # Reorder the columns in the Geopandas dataframe\n",
    "toronto_gdf.head() # Display top 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 4. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In this section, I used the Geopy library to obtain the coordinates for Toronto and made a scatter map of all the 140 neighbourhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "address = 'Toronto' # name of city we want the location coordinates\n",
    "geolocator = Nominatim(user_agent=\"toronto_explorer\") # user agent. You can use any name\n",
    "location = geolocator.geocode(address)\n",
    "tor_lat = location.latitude # store longitude value\n",
    "tor_lon = location.longitude # store latitude value\n",
    "\n",
    "print(tor_lat,tor_lon )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "MAPBOX_ACCESSTOKEN='pk.eyJ1IjoiamVzcy1kYXRhIiwiYSI6ImNraGxzcTE0MzFibDIycHFrZHV0ZzIwejYifQ.rmOTEpw-SZSoQO4cnUuEIg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accesstoken = MAPBOX_ACCESSTOKEN  # Replace with your Mapbox Access Token\n",
    "\n",
    "# Plotly Express Scatter_Mapbox Initialization\n",
    "tor_map = px.scatter_mapbox(toronto_gdf, # Geopandas dataframe\n",
    "                            lat=\"LATITUDE\", # Latitude column in the Geopandas dataframe\n",
    "                            lon=\"LONGITUDE\", # Longitude column in the Geopandas dataframe\n",
    "                            hover_name=\"Neighbourhood Name\", # Hover name for the various points\n",
    "                            hover_data=[\"Neighbourhood ID\"], # Include additional data to hover frame\n",
    "                            color_discrete_sequence=[\"blue\"], # Colour of data points\n",
    "                            center={\n",
    "                                'lat': tor_lat,\n",
    "                                'lon': tor_lon\n",
    "                            },\n",
    "                            zoom=9, # Initial Zoom size of plot\n",
    "                            height=400,\n",
    "                            title=\"Map of Toronto and its 140 Neighbourhoods\")\n",
    "tor_map.update_layout(margin={\"r\": 0, \"t\": 30, \"l\": 0, \"b\": 0}) # set margins of plot\n",
    "tor_map.update_layout(mapbox_style=\"streets\",\n",
    "                      mapbox=dict(bearing=-15, accesstoken=MAPBOX_ACCESSTOKEN))\n",
    "\n",
    "tor_map.show() # Render map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 5. Toronto Neighbourhoods Venues Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In this section, the goal was to obtain top 100 venues present in each Toronto neighbourhood. This was done using the Foursquare API and my user credentials.\n",
    "NOTE: You can get your credentials from the Foursquare website. You need to store your credentials in these variables i.e. CLIENT_ID, CLIENT_SECRET, LIMIT. The limit was set at 100 locations for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the '#' sign below and enter your credentials from Foursquare website\n",
    "# CLIENT_ID = '   ', CLIENT_SECRET = '  ', LIMIT = '   '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "CLIENT_ID = '3UHJFL2OXCQ0SDFMLYSC2SMMS0D4CAEXHVFGAJUTCSHKULBH' # Foursquare ID\n",
    "CLIENT_SECRET = 'WPJPGVZ5L3WCI4FZ0WWTUHWLK52FHDZ1ILCNZRWXHCEC2ERW' # Foursquare Secret Key\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "LIMIT = 100 # A default Foursquare API limit value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Define Function to obtain all Venues in each neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
    "\n",
    "    venues_list = []\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "\n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, CLIENT_SECRET, VERSION, lat, lng, radius, LIMIT)\n",
    "\n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "\n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(name, lat, lng, v['venue']['name'],\n",
    "                             v['venue']['categories'][0]['name'])\n",
    "                            for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame(\n",
    "        [item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighbourhood Name', 'Neighbourhood Latitude',\n",
    "        'Neighbourhood Longitude', 'Venue', 'Venue Category']\n",
    "\n",
    "    return (nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use the function created above to obtain Venues and Venue Catgories for each Neighbourhood\n",
    "toronto_venues = getNearbyVenues(names=toronto_gdf['Neighbourhood Name'],\n",
    "                                 latitudes=toronto_gdf['LATITUDE'],\n",
    "                                 longitudes=toronto_gdf['LONGITUDE'])\n",
    "toronto_venues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} unique neighbourhoods were returned with >1 venues'.format(\n",
    "    toronto_venues['Neighbourhood Name'].nunique()))\n",
    "print('{} venues were returned'.format(toronto_venues.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can see that only 138 neighbourhoods were returned. P.S: I did a check using \"Left Join\" to see which neighbourhoods did not return any venues and they were St.Andrew-Windfields and Willowridge-Martingrove-Richview."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Summary of Results from Data Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tor_count = toronto_venues.groupby(\n",
    "    'Neighbourhood Name').count()  # Group Neighbourhoods and return count of all venues\n",
    "tor_count.reset_index(inplace=True)\n",
    "print('There are {} unique categories.'.format(\n",
    "    len(toronto_venues['Venue Category'].unique()\n",
    "print('The least number of venues for a Neighbourhood is {}.'.format(\n",
    "    tor_count['Venue Category'].min()))\n",
    "print('The most number of venues for a Neighbourhood is {}.'.format(\n",
    "    tor_count['Venue Category'].max()))\n",
    "print('These are the neighbourhoods with least venues:\\n{} '.format(\n",
    "    tor_count['Neighbourhood Name'][tor_count['Venue Category'] == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 6. Analyzing Toronto Neighbourhoods & Venues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### One-hot Encoding\n",
    "Firstly, One-hot encoding was used to convert venue categories to numerical formats for each neighbourhood. This helped me carry out further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "toronto_onehot = pd.get_dummies(toronto_venues[['Venue Category']],\n",
    "                                prefix=\"\",\n",
    "                                prefix_sep=\"\") # Remove Prefix 'Venue Category' from column names\n",
    "\n",
    "# add neighborhood name column back to dataframe\n",
    "toronto_onehot['Neighbourhood Name'] = toronto_venues['Neighbourhood Name']\n",
    "\n",
    "# move neighborhood column to the first column\n",
    "neigh = toronto_onehot['Neighbourhood Name']\n",
    "toronto_onehot.drop(labels=['Neighbourhood Name'], axis=1, inplace=True)\n",
    "toronto_onehot.insert(0, 'Neighbourhood Name', neigh)\n",
    "toronto_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Group and Sum up all Venue categories for each neighbourhood\n",
    "toronto_grouped = toronto_onehot.groupby('Neighbourhood Name').sum().reset_index()\n",
    "toronto_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Analysis of Top Venues in Toronto\n",
    "This was done to obtain the venue categories with the highest frequency in Toronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a copy of the toronto_grouped dataframe to carry out further analysis\n",
    "tem = toronto_grouped.copy(deep=True)  \n",
    "# This method prevents changes being made to the original dataframe\n",
    "tem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to transpose the dataframe above by removing the Neighbourhood name\n",
    "tem.rename(columns={'Neighbourhood Name':''},inplace=True)\n",
    "tem=tem.set_index('').T # Transpose function\n",
    "tem.reset_index(inplace=True)\n",
    "tem.rename(columns={'index':'Venues','Neighbourhood Name':''},inplace=True) # Rename columns\n",
    "tem['Total'] = tem.sum(axis=1) # Obtain Sum of all venue catrgories\n",
    "tem=tem[['Venues','Total']] # Slice dataframe to show only relevant columns\n",
    "tem=tem.sort_values(by='Total', ascending=False) # Sort venue categories in descending order\n",
    "tem.head() # Display top 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Top Venues in Toronto\n",
    "The plot was made using Plotly Express Library. Try exploring the bar chart and click/tap on a legend value to isolate a category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the toronto_grouped dataframe again\n",
    "tem2=toronto_grouped.copy(deep=True)\n",
    "tem2['Total']=tem2.sum(axis=1)\n",
    "tem2=tem2[['Neighbourhood Name','Total']] # Slice dataframe\n",
    "tem2=tem2.sort_values(by='Total', ascending=False) # Sort Neighbourhood name in descending order\n",
    "tem2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topvenues_barchart = px.bar(tem2.query(\"Total>48\"),\n",
    "                            x=\"Neighbourhood Name\",\n",
    "                            y=\"Total\", \n",
    "                            color=\"Neighbourhood Name\")\n",
    "\n",
    "topvenues_barchart.update_layout(title = 'Toronto Neighbourhoods with most venues',\n",
    "                         margin={\"r\":0,\"t\":30,\"l\":0,\"b\":0})\n",
    "\n",
    "topvenues_barchart.update_xaxes(showticklabels=False) # Removed tick labels as it was too long\n",
    "topvenues_barchart.show() # Display plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Extracting Essential Venue Categories\n",
    "In this section, I attempted to extract all **essential venues** from the larger dataset 'toronto_grouped'. These venues included Restaurants, Bus Station, Bus Stop, Convenience Store, Bank, Train Station, Park, Playground, School, Discount Store, Metro Station and Shopping Malls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter all Restaurant sub-categories into one dataframe 'temp'\n",
    "temp=toronto_grouped[toronto_grouped.filter(regex='Restaurant|Neighbourhood Name').columns].copy(deep=True)\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['Restaurant'] = temp.sum(axis=1) # Obtain sum of all restaurants per neighbourhood\n",
    "temp=temp[['Neighbourhood Name', 'Restaurant']] # Slice dataframe \n",
    "# Extract remaining essential venue categories to one dataframe\n",
    "toronto_venues_sorted = toronto_grouped.loc[:,\n",
    "                                            ('Neighbourhood Name',\n",
    "                                             'Bus Station', 'Bus Stop',\n",
    "                                             'Convenience Store', 'Bank',\n",
    "                                             'Train Station', 'Park',\n",
    "                                             'Playground', 'School',\n",
    "                                             'Discount Store', 'Metro Station',\n",
    "                                             'Shopping Mall')]\n",
    "\n",
    "# Merge Restaurants and other essential venue categories together\n",
    "toronto_venues_sorted = toronto_venues_sorted.merge(temp,\n",
    "                                                    on='Neighbourhood Name')\n",
    "toronto_venues_sorted.head() # Display 1st 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Analyzing Neighbourhoods with most essential venue categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calulate the total number of essential venues per neighbourhood\n",
    "toronto_venues_sorted['Total']=toronto_venues_sorted.sum(axis=1)\n",
    "# Create new dataframe to store all neighbourhoods and their total number of essential venues\n",
    "total_venues=toronto_venues_sorted[['Neighbourhood Name','Total']]\n",
    "total_venues.sort_values(by=['Total'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 7. Machine Learning Algorithm (k-Means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "_**k-means**_ is an Unsupervised Machine Learning algorithm that groups data into k number of clusters. This method uses a centroid based algorithm to group the neighbourhoods into “k” clusters such that all neighbourhoods with similar characteristics or qualities are in the same cluster. The algorithm works in the following steps:\n",
    "* Determine most optimal k (i.e. no of clusters)\n",
    "* Initialize k such that initial means are randomly generated within the data domain\n",
    "* k clusters are created by associating every observation with the nearest mean\n",
    "* The centroid of each of the k clusters becomes the new mean\n",
    "* Steps (iii and iv) are repeated until convergence is reached such that all data points belong to a cluster that are significantly distinct from one another\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Determining Optimum number of Clusters (Elbow Method)\n",
    "For this method, the dataset is fit with the k-means model for a range of values (1-10). The distortions for each value of k is stored and then plotted on a line chart. The point of inflection is a good indication that the model fits best at that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe and drop 'Neighbourhood name' as ML algorithm can be done \n",
    "# for only numerical values\n",
    "venues_clustering = total_venues.drop('Neighbourhood Name', 1).copy(deep=True)\n",
    "distortions = [] # Store results on distortions in a list\n",
    "K = range(1, 10) # Initialize k\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k) # Initialize kMeans model\n",
    "    kmeanModel.fit(venues_clustering) # Fit model to dataset\n",
    "    distortions.append(kmeanModel.inertia_) # Append distortions to list for each k value\n",
    "# use matplotlib to plot function\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KneeLocator is used to compute the point of inflection\n",
    "# especially when it is difficult to locate the point of inflection from the curve above\n",
    "from kneed import KneeLocator\n",
    "kl = KneeLocator(range(1, 10),\n",
    "                 distortions,\n",
    "                 curve=\"convex\",\n",
    "                 direction=\"decreasing\")\n",
    "print('The optimum number of clusters is: ' + str(kl.elbow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 8. Clustering Neighbourhoods by Total number of Essential Venues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Using the optimum number of clusters obtained from the Elbow method, the neighbourhoods were grouped into 3 clusters using k-means algorithm based on the number of essential venues that were available in them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run k-means clustering by initializing no. of clusters and fitting the model\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(venues_clustering)\n",
    "\n",
    "# add clustering labels to original dataframe\n",
    "total_venues.insert(2, 'Cluster Labels', kmeans.labels_)\n",
    "\n",
    "# Make a copy of the original geopandas dataframe\n",
    "toronto_venues_map = toronto_gdf.copy(deep=True)\n",
    "\n",
    "# merge total_venues data with Geopandas dataframe, toronto_venues_map\n",
    "toronto_venues_map = pd.merge(total_venues.set_index('Neighbourhood Name'),\n",
    "                              toronto_venues_map,\n",
    "                              how='outer',\n",
    "                              on='Neighbourhood Name')\n",
    "\n",
    "# The next line of code was used to fill in Cluster label values for the 2 neighbourhoods \n",
    "# that had no venues from Section 5. Venues in Cluster 0 had the least number of venues.\n",
    "toronto_venues_map.fillna(value=0, inplace=True)\n",
    "# Convert Cluster Labels and Total values to interger type\n",
    "toronto_venues_map['Cluster Labels'] = toronto_venues_map[\n",
    "    'Cluster Labels'].astype('int64')\n",
    "toronto_venues_map['Total'] = toronto_venues_map['Total'].astype('int64')\n",
    "toronto_venues_map.head() # Display first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 9. Visualizing Toronto Neighbourhoods Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Based on the outcome of the clustering attempt described above, the 140 Toronto neighbourhoods were visualized with the aids of Sunburst and Choropleth Maps using Plotly Express."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Obtain all Toronto districts from an exisitng dataset.\n",
    "districts = pd.read_excel(r'C:\\Users\\Osas\\Downloads\\Data analysis\\Capstone\\Housing.xlsx',sheet_name='Sheet2')\n",
    "# Drop Neighbourhood Name column\n",
    "districts = districts.drop(labels='Neighbourhood Name', axis=1)\n",
    "essential_venues = toronto_venues_map[['Neighbourhood Name', 'Neighbourhood ID', 'Total']].copy(deep=True)\n",
    "essential_venues = essential_venues.rename(columns={'Total': 'Total Essential Venues'})\n",
    "# Merge districts and essential venues dataframe\n",
    "essential_venues = pd.merge(essential_venues, districts, on='Neighbourhood ID')\n",
    "essential_venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Sunburst Chart for Toronto Neighbourhoods and Districts\n",
    "This was created using Plotly library. Explore the chart by clicking or tapping on a district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues_chart = px.sunburst(\n",
    "    essential_venues # ,\n",
    "    path=['District', 'Neighbourhood Name'] # ,\n",
    "    values='Total Essential Venues',\n",
    "    title='Toronto Neighbourhoods and Districts showing Essential Venues',\n",
    "    hover_name='Neighbourhood Name')\n",
    "\n",
    "venues_chart.update_layout(margin=dict(t=40, l=0, r=0, b=0))\n",
    "venues_chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Analyzing Neighbourhood Clusters based on Total number of Essential Venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean number of essential venues per cluster\n",
    "temp5 = total_venues.groupby('Cluster Labels').mean().reset_index()\n",
    "temp5.rename(columns={'Total':'Mean'},inplace=True)\n",
    "temp5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the results above that Cluster 0 has the neighbourhoods with an average of 2 essential venues while Cluster 1 and 2 have 19 and 8 venues respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Neighbourhoods in Cluster 2 have {}-{} venues'.format(\n",
    "    total_venues.loc[total_venues['Cluster Labels'] == 2, 'Total'].min(),\n",
    "    total_venues.loc[total_venues['Cluster Labels'] == 2, 'Total'].max()))\n",
    "print('Neighbourhoods in Cluster 1 have {}-{} venues'.format(\n",
    "    total_venues.loc[total_venues['Cluster Labels'] == 1, 'Total'].min(),\n",
    "    total_venues.loc[total_venues['Cluster Labels'] == 1, 'Total'].max()))\n",
    "print('Neighbourhoods in Cluster 2 have {}-{} venues'.format(\n",
    "    total_venues.loc[total_venues['Cluster Labels'] == 0, 'Total'].min(),\n",
    "    total_venues.loc[total_venues['Cluster Labels'] == 0, 'Total'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Neighbourhoods Venues Density Map\n",
    "This plot was moved to the Final Map plot in [Section 12](#13.-Final-Results-and-Visualizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index to Neighbourhood ID to match the index in the GeoJSON file created below\n",
    "toronto_venues_map=toronto_venues_map.set_index('Neighbourhood ID')\n",
    "# Rename column 'Cluster Labels' column to aid Visualization \n",
    "toronto_venues_map.rename(columns={'Cluster Labels': 'Venues Density'},\n",
    "                          inplace=True)\n",
    "# Change cluster label values to String values for better visualization\n",
    "toronto_venues_map['Venues Density'] = toronto_venues_map[\n",
    "    'Venues Density'].replace([0, 1, 2], [\"Low\", \"High\", \"Mid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Geopandas to GeoJSON file for use on Plotly visualizations\n",
    "toronto_json= toronto_gdf\n",
    "toronto_json= toronto_json.set_index('Neighbourhood ID')\n",
    "toronto_json = toronto_json.to_crs(epsg=4326) # convert the coordinate reference system to lat/long\n",
    "toronto_json = toronto_json.__geo_interface__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 10. Import and Clean Primary Benchmarks Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The primary benchmarks are Unemployment, Crime and COVID-19 rates. These were in with excel or csv formats and were read in a Pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COVID-19 Rate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read dataframe into a Pandas dataframe\n",
    "covid_rate = pd.read_excel(r'C:\\Users\\Osas\\Downloads\\Data analysis\\Capstone\\CityofToronto_COVID-19_NeighbourhoodData.xlsx',\n",
    "                            sheet_name='All Cases and Rates by Neighbou')\n",
    "# Drop missing values. This is of no consequence to our dataset\n",
    "covid_rate.dropna(axis=0, inplace=True)\n",
    "covid_rate = covid_rate.astype({\"Neighbourhood ID\": int})\n",
    "# Extract relevant columns\n",
    "cols = ['Neighbourhood Name', 'Neighbourhood ID', 'Rate per 100,000 people']\n",
    "covid_rate = covid_rate[cols]\n",
    "covid_rate.columns = ['Neighbourhood Name', 'Neighbourhood ID', 'Covid-19 Rate']\n",
    "# Only Neighbourhood ID and COVID-19 rate were important as we do a merge operation later\n",
    "covid_rate = covid_rate[['Neighbourhood ID', 'Covid-19 Rate']]\n",
    "covid_rate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment Rate Dataset\n",
    "This dataset was part of a larger Census dataset as we will see below. I locate the exact row that had my data and used the row number to slice the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Census dataset\n",
    "dem_data = pd.read_csv(r'C:\\Users\\Osas\\Downloads\\Data analysis\\Capstone\\Employment & Demographics - 2016.csv')\n",
    "dem_data.head() # Display first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the row number for Unemployment rate to allow us extract it from the dataframe\n",
    "dem_data.index[dem_data['Characteristic'] == 'Unemployment rate'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice demographics dataframe to obtain Unemployment rates per Neighbourhood\n",
    "emp_data=dem_data.iloc[lambda df: [0,1890], 4:]\n",
    "emp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns\n",
    "emp_data.drop(labels='City of Toronto',axis=1, inplace=True)\n",
    "emp_data.rename(columns={'Characteristic':'Neighbourhood Name'}, inplace=True)\n",
    "# Set index and Transpose\n",
    "emp_data=emp_data.set_index('Neighbourhood Name').T\n",
    "emp_data.reset_index(inplace = True)\n",
    "# Re-order columns\n",
    "emp_data.columns = ['Neighbourhood Name', 'Neighbourhood ID', 'Unemployment Rate']\n",
    "# Set Neighbourhood ID and Unemployment Rate to numeric type\n",
    "emp_data['Neighbourhood ID']=emp_data['Neighbourhood ID'].apply(pd.to_numeric) \n",
    "emp_data['Unemployment Rate']=emp_data['Unemployment Rate'].apply(pd.to_numeric) \n",
    "emp_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crime Rate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_data_raw = pd.read_csv(r'C:\\Users\\Osas\\Downloads\\Data analysis\\Capstone\\Neighbourhood Crime Rates.csv')\n",
    "crime_data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_data = crime_data_raw.copy(deep=True)\n",
    "# Assign variable name to list of relevant columns\n",
    "col_list = ['Assault_2019', 'AutoTheft_2019', 'BreakandEnter_2019', 'Homicide_2019',\n",
    "            'Robbery_2019', 'TheftOver_2019']\n",
    "# Obtain Crime rate for each neighbourhood\n",
    "crime_data['Crime_Rate'] = 100000 * (crime_data[col_list].sum(axis=1) /\n",
    "                                     crime_data['Population'])\n",
    "crime_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract only relevant columns from Crime dataset\n",
    "cols=['Neighbourhood','Hood_ID','Crime_Rate']\n",
    "crime_data=crime_data[cols]\n",
    "crime_data.columns=['Neighbourhood Name', 'Neighbourhood ID', 'Crime Rate']\n",
    "crime_data=crime_data[['Neighbourhood ID', 'Crime Rate']]\n",
    "crime_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Primary Benchmarks Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge unemployment and crime data first with Neighbourhood ID as primary key\n",
    "cluster_data=pd.merge(emp_data, crime_data, on=['Neighbourhood ID'])\n",
    "cluster_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge above dataframe with COVID-19 dataset\n",
    "cluster_data=pd.merge(cluster_data, covid_rate, on=['Neighbourhood ID'])\n",
    "cluster_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Data Exploration (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics for Primary Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Descriptive stats of the dataframe\n",
    "cluster_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the dataframe above, we can see that the average Unemployment rate for City of Toronto is 8.3% for 2019. Average number of crimes committed per 100,000 people is 1378 and 1 in 100 persons has contracted COVID-19 as of October 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bubble Plot for Primary Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubble_data = pd.merge(cluster_data,districts, on='Neighbourhood ID')\n",
    "bubble_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubble_chart = px.scatter(bubble_data, # Dataframe\n",
    "                        x=\"Unemployment Rate\", # Column name for x-values\n",
    "                        y=\"Covid-19 Rate\", # Column name for y-values\n",
    "                        size=\"Crime Rate\", # column name for size of bubble\n",
    "                        color=\"District\", # Column name for Legend\n",
    "                        hover_data=({\n",
    "                        'Unemployment Rate': ':.2f', # Set the no. of decimal places\n",
    "                        'Crime Rate': ':.2f',\n",
    "                        'Covid-19 Rate': ':.2f'}),\n",
    "                        hover_name=\"Neighbourhood Name\",\n",
    "                        size_max=45, # maximum bubble size\n",
    "                        title='Exploring Toronto Neighbourhoods using Primary Benchmarks')\n",
    "bubble_chart.update_layout(width=800,\n",
    "                           height=600,\n",
    "                           margin={\"r\": 0,\"t\": 75, \"l\": 0, \"b\": 0})\n",
    "bubble_chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can see that Neighbourhoods with highest crime rate are in Old Toronto while the neighbourhood with the highest unemployment rate is in Oakridge, Scarborough District. Hover on the plot and Click/Tap on the legend on the Bubble chart to isolate a district and explore further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 11. Clustering Neighbourhoods by Primary Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Determine Optimum Number of Clusters with Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster_data=cluster_data.copy(deep=True) # make a new dataframe for clustering\n",
    "# Drop columns not required for the clustering algorithm\n",
    "Clustering_1 = Cluster_data.drop(labels=['Neighbourhood Name','Neighbourhood ID'], axis=1)\n",
    "\n",
    "# Use Elbow Method to get optimum number of clusters. Same process as used for Clustering in Section 8\n",
    "distortions = []\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k)\n",
    "    kmeanModel.fit(Clustering_1)\n",
    "    distortions.append(kmeanModel.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import KneeLocator\n",
    "kl = KneeLocator(range(1, 10), distortions, curve=\"convex\", direction=\"decreasing\")\n",
    "print('The optimum number of clusters is: ' + str(kl.elbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of clusters\n",
    "kclusters = 3\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(Clustering_1)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Analyzing Neighbourhood Clusters based on Primary Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clustering labels to original dataframe\n",
    "Cluster_data.insert(2, 'Cluster Labels', kmeans.labels_)\n",
    "Cluster_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean rate of each Cluster\n",
    "Cluster_data.groupby('Cluster Labels').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above that Cluster 1 have the lowest primary benchmarks. This cluster was then used in the second clustering attempt using Secondary benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Neighbourhood Clusters based on Primary Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare bar-chart dataset. \n",
    "Bardata1=Cluster_data.groupby('Cluster Labels').count()\n",
    "Bardata1.reset_index(inplace=True)\n",
    "Bardata1=Bardata1[['Cluster Labels','Neighbourhood Name']] # Extract relevant columns for plot\n",
    "Bardata1.columns=(['Cluster Labels','Total Neighbourhoods'])\n",
    "\n",
    "# Change Cluster labels to categorical values for seamless visualization\n",
    "Bardata1[\"Cluster Labels\"] = pd.Categorical(Bardata1[\"Cluster Labels\"], [1, 0, 2]) \n",
    "Bardata1.sort_values(\"Cluster Labels\", inplace=True)\n",
    "# Rename cluster labels based on outcome for easy visualization\n",
    "Bardata1[\"Cluster Labels\"]=Bardata1[\"Cluster Labels\"].replace([1, 0, 2], \n",
    "           [\"Low\", \"Mid\", \"High\"])\n",
    "Bardata1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Barchart for Clustering using Primary benchmarks done with Plotly Express\n",
    "cluster_barchart = px.bar(Bardata1, x=\"Cluster Labels\", y=\"Total Neighbourhoods\",  color=\"Cluster Labels\", \n",
    "                          text='Total Neighbourhoods', category_orders={\"Cluster Labels\": [\"1\", \"0\", \"2\"]})\n",
    "\n",
    "    \n",
    "cluster_barchart.update_xaxes(type='category')\n",
    "cluster_barchart.update_layout(title = 'Clustering Distribution using Primary Benchmarks',\n",
    "                         margin={\"r\":0,\"t\":30,\"l\":0,\"b\":0})\n",
    "cluster_barchart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Clustering using Secondary Benchmark (Housing Prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Using the outcome of the clustering attempt in Section 11, the 109 neighbourhoods in the Low Cluster were further grouped based on their Housing prices (for one-bedroom apartment). The Housing prices were considered as secondary benchmark. The outcome of this final clustering attempt was used to generate the final Neighbourhood Desirability Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe for Neighbourhoods in the \"Low\" Cluster from section 11\n",
    "BestCluster=Cluster_data[Cluster_data['Cluster Labels'] == 1].copy(deep=True)\n",
    "# Extract only relevant columns\n",
    "Best_Cluster=BestCluster.drop(columns=['Cluster Labels', 'Unemployment Rate', 'Crime Rate','Covid-19 Rate'])\n",
    "Best_Cluster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Housing Prices Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing=pd.read_excel(r'C:\\Users\\Osas\\Downloads\\Data analysis\\Capstone\\Housing.xlsx',sheet_name='Sheet1')\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the $ for the Rent column and drop the Neighbourhood Name column\n",
    "housing['Median Rent']=housing['Median Rent'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "housing.drop(columns=['Neighbourhood Name'], inplace=True)\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_Cluster=Best_Cluster.merge(housing,on=['Neighbourhood ID'])\n",
    "Best_Cluster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Determine Optimum Number of Clusters with Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clustering_2 = Best_Cluster.drop(labels=['Neighbourhood Name','Neighbourhood ID'], axis=1)\n",
    "distortions2 = []\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k)\n",
    "    kmeanModel.fit(Clustering_2)\n",
    "    distortions2.append(kmeanModel.inertia_)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, distortions2, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import KneeLocator\n",
    "kl = KneeLocator(range(1, 10), distortions2, curve=\"convex\", direction=\"decreasing\")\n",
    "print('The optimum number of clusters is: ' + str(kl.elbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of clusters\n",
    "kclusters = 3\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(Clustering_2)\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Analyzing Neighbourhood Clusters based on Secondary Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Cluster labels to original dataframe\n",
    "Best_Cluster.insert(2, 'Cluster Labels', kmeans.labels_)\n",
    "Best_Cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_Cluster.groupby('Cluster Labels').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "From the dataframe above, we can see that neighbourhoods in Cluster 0 have the lowest housing prices while neighbourhoods in Cluster 2 and 1 are the mid and high range respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For better visualization, replace Cluster label values 1 and 2 so that they are in ascending order\n",
    "Best_Cluster['Cluster Labels']=Best_Cluster['Cluster Labels'].replace(to_replace=[1,2], value=[2,1])\n",
    "Best_Cluster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Visualizing Neighbourhood Clusters based on Secondary Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group neighbourhoods from Clustering attempt with Secondary benchmark\n",
    "Bardata2=Best_Cluster.copy(deep=True)\n",
    "Bardata2=Best_Cluster.groupby('Cluster Labels').count()\n",
    "Bardata2.reset_index(inplace=True)\n",
    "Bardata2=Bardata2[['Cluster Labels','Neighbourhood Name']]\n",
    "# Rename columns\n",
    "Bardata2.columns=(['Cluster Labels','Total Neighbourhoods'])\n",
    "# Rename cluster labels\n",
    "Bardata2[\"Cluster Labels\"]=Bardata2[\"Cluster Labels\"].replace([0, 1, 2], \n",
    "           [\"Low\", \"Mid\", \"High\"])\n",
    "Bardata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart from Clustering using Secondary benchmark\n",
    "cluster_barchart2 = px.bar(Bardata2, x=\"Cluster Labels\", y=\"Total Neighbourhoods\",  color=\"Cluster Labels\", \n",
    "                          text='Total Neighbourhoods', category_orders={\"Cluster Labels\": [\"0\", \"1\", \"2\"]})\n",
    "              \n",
    "cluster_barchart2.update_xaxes(type='category')\n",
    "cluster_barchart2.update_layout(title = 'Clustering Distribution of \"Best\" Neighbourhoods using Housing Prices',\n",
    "                         margin={\"r\":0,\"t\":30,\"l\":0,\"b\":0})\n",
    "cluster_barchart2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 13. Final Results and Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The results from the second clustering attempt in Secction 12 were used to rank the neighbourhoods into 4 categories. The neighbourhoods that belonged to the “Mid” and “High” clusters using _primary benchmarks_ were classified as the **_Least desirable_** neighbourhoods while those with \"Low\", \"Mid\" and \"High\" clusters using housing prices were classified as **_Most Desirable, Desirable and Semi-Desirable_** respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get results from clustering attempts using secondary benchmark in a new datframe\n",
    "Best_Cluster1=Best_Cluster[['Neighbourhood ID','Cluster Labels']].copy(deep=True)\n",
    "# Create a copy of the Geopandas dataframe to help with final map visualization\n",
    "housing_map=toronto_gdf.copy(deep=True)\n",
    "# Join the Best_Cluster1 with the Geopandas dataframe\n",
    "housing_map = housing_map.join(Best_Cluster1.set_index('Neighbourhood ID'), on='Neighbourhood ID')\n",
    "# Set index to Neighbourhood ID. This is helpful for map visualizations\n",
    "housing_map=housing_map.set_index('Neighbourhood ID')\n",
    "# For neighbourhoods in Mid and High Clusters from Section 11, they will have NaN values\n",
    "# The NaN values are now replaced with number 3 so they become the 4 clusters\n",
    "housing_map['Cluster Labels']=housing_map['Cluster Labels'].fillna(value=3)\n",
    "# Rename Cluster Labels column\n",
    "housing_map.rename(columns={'Cluster Labels': 'Neighbourhood Desirability Index'},inplace=True)\n",
    "# Change column data type\n",
    "housing_map['Neighbourhood Desirability Index']=housing_map['Neighbourhood Desirability Index'].astype('int64')\n",
    "housing_map.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Final distribution of Toronto Neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show distribution of all neighbourhoods\n",
    "hist_data=housing_map.copy(deep=True)\n",
    "hist_data['Neighbourhood Desirability Index']=hist_data['Neighbourhood Desirability Index'].replace([0, 1, 2, 3], \n",
    "           [\"Most Desirable\",\"Desirable\",\"Semi-Desirable\",\"Least Desirable\"])\n",
    "# I used the historgram type here because I wanted it to automatically compute the count for each category\n",
    "Hist = px.histogram(hist_data, x=\"Neighbourhood Desirability Index\", color = \"Neighbourhood Desirability Index\", \n",
    "                   title ='Distribution of Toronto Neighbourhoods based on Desirabilty Index')\n",
    "Hist.update_yaxes(title_text='Total Neighbourhoods', title_standoff=1)\n",
    "Hist.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we can see that only 7 neighbourhoods fell into the **Most Desirable index** rank while about 59% of the Toronto neighbourhoods were grouped into the **Desirable** category based on their medium housing prices and relatively low crime, COVID-19 and Crime rates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Merging Essential Venues and Neighbourhood Desirability Index Datasets\n",
    "\n",
    "In order to satisfy my curiosity, I wanted to know if neighbourhoods that had high number of *essential venues* were also in the *Most Desirable/Desirable* Category. This was achieved with the lines of code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "options = ['Most Desirable','Desirable'] \n",
    "\n",
    "df1=housing_map[housing_map['Neighbourhood Desirability Index'].isin(options)]\n",
    "\n",
    "df2=total_venues.sort_values(by=['Total'], ascending=False).head(20)\n",
    "\n",
    "result= pd.merge(df1, df2, how='inner', on=['Neighbourhood Name'])\n",
    "result=result.sort_values(by=['Total'], ascending=False)\n",
    "cols=['Neighbourhood Name', 'Neighbourhood Desirability Index', 'Total']\n",
    "result = result[cols]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can see that none of the neighbourhoods with high venue density fell into the Most Desirable Category. This is expected because with proximity to essential venues, housing prices increase. However, some of the neighbourhoods fell into the desirable category as seen above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Final Toronto Neighbourhoods Map\n",
    "This map merged the two outcomes i.e. **'Neighbourhood Desirability Index' and \"Venues Density\"** with all the major datasets into one choropleth map. This was achieved using the line of code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Defining Colour Scale for Discrete Neighbourhood Desirability Index and Venues Density Maps\n",
    "Due to the nature of Plotly library, we cannot define or customize colour bars for categorical variables on the Choropleth Graph Objects trace. Thanks to research, I learned the code below from *Kyle Pastor's* Medium article on how to create a colour scale for discrete/categorical variables and use on Plotly Graph objects. P.S. I had done the plots using Plotly Express and it worked fine with the categorical variables but for some reason, Graph objects does not allow this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDiscreteColourScale(colour_set):\n",
    "    #colour set is a list of lists\n",
    "    colour_output = []\n",
    "    num_colours = len(colour_set)\n",
    "    divisions = 1./num_colours\n",
    "    c_index = 0.\n",
    "    # Loop over the colour set\n",
    "    for cset in colour_set:\n",
    "        num_subs = len(cset)\n",
    "        sub_divisions = divisions/num_subs\n",
    "        # Loop over the sub colours in this set\n",
    "        for subcset in cset:\n",
    "            colour_output.append((c_index,subcset))\n",
    "            colour_output.append((c_index + sub_divisions-\n",
    "                .001,subcset))\n",
    "            c_index = c_index + sub_divisions\n",
    "    colour_output[-1]=(1,colour_output[-1][1])\n",
    "    return colour_output\n",
    "\n",
    "color_schemes = [\n",
    "    ['rgb(254,224,210)'],\n",
    "    ['rgb(244,165,130)'],\n",
    "    ['rgb(214,96,77)'],\n",
    "    ['rgb(178,24,43)']\n",
    "]\n",
    "\n",
    "color_schemes2 = [\n",
    "    ['rgb(254,196,79)'] ,\n",
    "    ['rgb(254,153,41)'],\n",
    "    ['rgb(204,76,2)']\n",
    "]\n",
    "colorscale = generateDiscreteColourScale(color_schemes) # Colour scheme for Neighbourhood Desirability Index map\n",
    "colorscale2 = generateDiscreteColourScale(color_schemes2) # Colour scehme for Venues Denisty Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Essential Venues Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy original dataframe\n",
    "venuesmap=toronto_venues_map.copy(deep=True)\n",
    "# Convert the categorical values from earlier to numerical values to allow us visualize on the choropleth map\n",
    "venuesmap['Venues Density']=venuesmap['Venues Density'].replace([\"Low\",\"Mid\",\"High\"],[0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Primary Benchmarks Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy orignal dataframe\n",
    "cluster_map=cluster_data.copy(deep=True)\n",
    "# Rename Columns. This is not necessary\n",
    "cluster_map.columns=['Neighbourhood_Name','Neighbourhood ID','Unemployment_Rate','Crime_Rate','Covid_19_Rate']\n",
    "# Set index to Neighbourhood ID. Same as GeoJSON dataset\n",
    "cluster_map=cluster_map.set_index('Neighbourhood ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Final Choropleth Map showing all relevant datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "This was done using Plotly Graph Objects library. I also added dropdown lists for all the datasets and for various Map styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Layout\n",
    "final_map = go.Figure()\n",
    "\n",
    "# Add Traces\n",
    "\n",
    "# Add first trace for Neighbourhood Desirability Index\n",
    "final_map.add_trace(\n",
    "    go.Choroplethmapbox(\n",
    "        geojson=toronto_json, # GeoJSON file\n",
    "        locations=housing_map.index, #index needs to be same as id element of GeoJSON\n",
    "        z=housing_map['Neighbourhood Desirability Index'], # set colour value\n",
    "        text=housing_map['Neighbourhood Name'], # sets the hover information for each datapoint\n",
    "        colorbar=dict(thickness=20, # sets attributes for the colour scale\n",
    "                      ticklen=3,\n",
    "                      outlinewidth=0,\n",
    "                      title=\"Neighbourhood Desirability Index\", # title of colour bar\n",
    "                      tickmode='array',\n",
    "                      nticks=4,\n",
    "                      tickvals=[0.2, 1, 2, 2.8], # set tick values that need to be renamed\n",
    "                      ticktext=[ \"Most Desirable\", \"Desirable\", \"Semi-Desirable\",\n",
    "                          \"Least Desirable\"]), # set tick text to replace tick values\n",
    "        marker_line_width=1,\n",
    "        marker_opacity=0.7,\n",
    "        colorscale=colorscale,  # set colourscale that was defined\n",
    "        hovertemplate=\"<b>%{text}</b><br>\" + \"Desirability Index: %{z}<br>\" +\n",
    "        \"<extra></extra>\", # sets the text format shown when you hover over each shape\n",
    "        visible=True)) # plot will be visible upon rendering\n",
    "\n",
    "# Add second trace for Unemployment Rate\n",
    "final_map.add_trace(\n",
    "    go.Choroplethmapbox(\n",
    "        geojson=toronto_json,  #GeoJSON\n",
    "        locations=cluster_map.index, #index needs to be same as id element of GeoJSON \n",
    "        z=cluster_map.Unemployment_Rate,  #sets the color value\n",
    "        text=cluster_map.Neighbourhood_Name,  #sets text for each shape\n",
    "        colorbar=dict(thickness=20,\n",
    "                      ticklen=3,\n",
    "                      outlinewidth=0,\n",
    "                      title=\"Unemployment Rate\", # title of colour bar\n",
    "                      ticksuffix='%'),  #adjusts the format of the colorbar\n",
    "        marker_line_width=1,\n",
    "        marker_opacity=0.7,\n",
    "        colorscale=\"Viridis_r\",  # set colour scale\n",
    "        hovertemplate=\"<b>%{text}</b><br>\" + \"Unemployment Rate: %{z}<br>\" +\n",
    "        \"<extra></extra>\", # sets the text format shown when you hover over each shape\n",
    "        visible=False))  # plot will not be visible upon rendering\n",
    "\n",
    "# Add third trace for Crime rate\n",
    "final_map.add_trace(\n",
    "    go.Choroplethmapbox(\n",
    "        geojson=toronto_json,\n",
    "        locations=cluster_map.index,  \n",
    "        z=cluster_map.Crime_Rate,\n",
    "        text=cluster_map.Neighbourhood_Name,\n",
    "        colorbar=dict(thickness=20,\n",
    "                      ticklen=3,\n",
    "                      outlinewidth=0,\n",
    "                      title=\"Crime Rate\"),\n",
    "        marker_line_width=1,\n",
    "        marker_opacity=0.7,\n",
    "        colorscale=\"YlOrRd\",\n",
    "        hovertemplate=\"<b>%{text}</b><br>\" + \"Crime Rate: %{z}<br>\" +\n",
    "        \"<extra></extra>\",\n",
    "        visible=False))\n",
    "\n",
    "# Add fourth trace for COVID_19 rate\n",
    "final_map.add_trace(\n",
    "    go.Choroplethmapbox(\n",
    "        geojson=toronto_json,\n",
    "        locations=cluster_map.\n",
    "        index,\n",
    "        z=cluster_map.Covid_19_Rate,\n",
    "        text=cluster_map.Neighbourhood_Name,\n",
    "        colorbar=dict(\n",
    "            thickness=20, ticklen=3, outlinewidth=0,\n",
    "            title=\"Covid-19 Rate\"),\n",
    "        marker_line_width=1,\n",
    "        marker_opacity=0.7,\n",
    "        colorscale=\"ice_r\",\n",
    "        hovertemplate=\"<b>%{text}</b><br>\" + \"Covid-19 Rate: %{z}<br>\" +\n",
    "        \"<extra></extra>\",\n",
    "        visible=False))\n",
    "\n",
    "# Add fifth trace for Essential Venues Density\n",
    "final_map.add_trace(\n",
    "    go.Choroplethmapbox(\n",
    "        geojson=toronto_json,\n",
    "        locations=venuesmap.index,\n",
    "        z=venuesmap['Venues Density'],\n",
    "        text=venuesmap['Neighbourhood Name'],\n",
    "        colorbar=dict(thickness=20,\n",
    "                      ticklen=3,\n",
    "                      outlinewidth=0,\n",
    "                      title=\"Venues Density\",\n",
    "                      tickmode='array',\n",
    "                      nticks=4,\n",
    "                      tickvals=[0.2, 1, 1.8],\n",
    "                      ticktext=[\"Low\", \"Mid\", \"High\"]),\n",
    "        marker_line_width=1,\n",
    "        marker_opacity=0.7,\n",
    "        colorscale=colorscale2,  # set colourscale that was defined\n",
    "        hovertemplate=\"<b>%{text}</b><br>\" + \"Desirability Index: %{z}<br>\" +\n",
    "        \"<extra></extra>\",\n",
    "        visible=False))\n",
    "\n",
    "# Create drop-down menus for all the datasets\n",
    "final_map.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"dropdown\", # set type of menu\n",
    "            direction=\"down\", # set direction of dropdown menu\n",
    "            showactive=True, # Show the selected label\n",
    "            x=0.75, # set horizontal position of the menu\n",
    "            xanchor=\"left\", # refernce point for x position\n",
    "            y=1.0, # set vertical position of the menu\n",
    "            yanchor=\"top\", # refernce point for y position\n",
    "            buttons=list([\n",
    "                dict(label=\"Desirability Index\", # Sets the Menu Option label\n",
    "                     method=\"update\", # updates the entire plot\n",
    "                     args=[{\n",
    "                         \"visible\": [True, False, False, False, False] # Sets the visibility when menu option is selected\n",
    "                     }, {\n",
    "                         \"title\": \"Toronto Neighbourhoods Desirability Index\"\n",
    "                     }]),\n",
    "                dict(label=\"Unemployment Rate\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\n",
    "                         \"visible\": [False, True, False, False, False]\n",
    "                     }, {\n",
    "                         \"title\":\n",
    "                         \"Unemployment Rate in Toronto Neighbourhoods\"\n",
    "                     }]),\n",
    "                dict(\n",
    "                    label=\"Crime Rate\",\n",
    "                    method=\"update\",\n",
    "                    args=[{\n",
    "                        \"visible\": [False, False, True, False, False]\n",
    "                    }, {\n",
    "                        \"title\":\n",
    "                        \"Crime Rate in Toronto Neighbourhoods (per 100,000 people)\"\n",
    "                    }]),\n",
    "                dict(\n",
    "                    label=\"Covid-19 Rate\",\n",
    "                    method=\"update\",\n",
    "                    args=[{\n",
    "                        \"visible\": [False, False, False, True, False]\n",
    "                    }, {\n",
    "                        \"title\":\n",
    "                        \"Covid-19 Rate in Toronto Neighbourhoods (per 100,000 people)\"\n",
    "                    }]),\n",
    "                dict(label=\"Venues Density\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\n",
    "                         \"visible\": [False, False, False, False, True]\n",
    "                     }, {\n",
    "                         \"title\": \"Toronto Neighbourhoods Venue Density\"\n",
    "                     }]),\n",
    "                dict(label=\"Clear All\",\n",
    "                     method=\"update\",\n",
    "                     args=[{\n",
    "                         \"visible\": [False, False, False, False, False]\n",
    "                     }, {\n",
    "                         \"title\": \"Toronto Neighbourhoods\"\n",
    "                     }])\n",
    "            ])),\n",
    " \n",
    "        \n",
    "# Menu options for Map styles\n",
    "        \n",
    "        dict(type=\"dropdown\",\n",
    "             direction=\"up\",\n",
    "             showactive=True,\n",
    "             x=0.75,\n",
    "             xanchor='left',\n",
    "             y=0.0,\n",
    "             yanchor='bottom',\n",
    "             buttons=list([\n",
    "                 dict(args=['mapbox.style', 'dark'],\n",
    "                      label='Dark',\n",
    "                      method='relayout'),\n",
    "                 dict(args=['mapbox.style', 'light'],\n",
    "                      label='Light',\n",
    "                      method='relayout'),\n",
    "                 dict(args=['mapbox.style', 'satellite'],\n",
    "                      label='Satellite',\n",
    "                      method='relayout'),\n",
    "                 dict(args=['mapbox.style', 'streets'],\n",
    "                      label='Streets',\n",
    "                      method='relayout')\n",
    "             ]))\n",
    "    ],\n",
    "    title={\n",
    "        'text': f\"Toronto Neighbourhoods Desirability Index\", # Inital plot title\n",
    "        'font': {'size': 20},\n",
    "        'xanchor': 'left'}, \n",
    "    mapbox1=dict(domain={'x': [0, 1], 'y': [0, 1]},\n",
    "                 center=dict(lat=tor_lat, lon=tor_lon),\n",
    "                 accesstoken=MAPBOX_ACCESSTOKEN,\n",
    "                 zoom=9.5,\n",
    "                 bearing=-12),\n",
    "    margin=dict(l=0, r=0, t=40, b=0))\n",
    "\n",
    "final_map.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thanks for viewing this Notebook. Check out my Medium post for a more concise report [here](https://jess-analytics.medium.com/analysis-of-toronto-neighbourhoods-using-machine-learning-291b942578f2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
